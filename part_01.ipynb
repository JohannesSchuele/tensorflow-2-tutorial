{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part_01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazemnejad/tensorflow-2-tutorial/blob/master/part_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8LoLU0OQha",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow 2.0 Tutorial: Part #1\n",
        "\n",
        "\n",
        "Deep Learning Group, Iran University of Science and Technology,\n",
        "\n",
        "*   Last Update: Dec 2019\n",
        "*   Official Page: https://github.com/iust-deep-learning/tensorflow-2-tutorial\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSj39l8gcIA8",
        "colab_type": "text"
      },
      "source": [
        "Please run the following cell before going through the rest of the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFC1dEyMcFq2",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from pprint import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVLck2lUOobQ",
        "colab_type": "text"
      },
      "source": [
        "## 1. Computation Graph\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvYRirIwugqz",
        "colab_type": "text"
      },
      "source": [
        "# What is Computational Graph\n",
        "The backbone of every TensorFlow program is what we call a **computational graph**. A computational graph is a way of thinking about mathematical expressions. Lets say we have the following expression:\n",
        "</br>\n",
        "$$\n",
        "h = (a + b)* (c + d)\n",
        "$$\n",
        "\n",
        "There are three operations in this expression, two additions and one multiplication. We can show this expression using the following graph:\n",
        "</br>\n",
        "</br>\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/kazemnejad/tensorflow-2-tutorial/master/resources/part_01_comp_graph.png\" width=\"200\" />\n",
        "<p align=\"left\">\n",
        "As you can see, every node in graph represents an operation or an input and every edge, which in TensorFlow we call a tensor, represents the data flow between these nodes (so in case you wonder where the name TensorFlow comes from, this is your answer). Almost every mathematical expression can be shown like this and it is not limited to neural networks. In a TensorFlow prgoram, we are simply creating a computational graph, hence we can benefit using TensorFlow in computing any kind of mathematical expression.\n",
        "</br>\n",
        "<p align=\"left\">\n",
        "But what are the advantages of a computational graph and why do we bother expressing our problem in this form in the first place?\n",
        "</br>\n",
        "The reason lies in the fact that some of our operations have nothing to do with each other and are completely independent. For example, in this case, two additions are independent. Using this graph form allows us to find these independent operations and compute their results in parallel. \n",
        "</br>\n",
        "Besides, recall the fact that nural networks use **back propagation** to optimize the loss function and this algorithm uses **chain rule** to compute the drivatives of loss function with respect to hidden variables. Therefore, TensorFlow benefits from this graph form which makes implementation of back propagation much easier.\n",
        "<p align=\"left\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctpex30furGu",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow behind the scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHgpKwC1O5ZX",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tensors, Variables, and OPS\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2seUQZwYcTe",
        "colab_type": "text"
      },
      "source": [
        "### Tensors\n",
        "Tensors are the main element that you will use to define your desired computations. Generally speaking, Tensors are n-dimensional arrays with a specified data type. That is, each component of the Tensors has the same data type (e.g., int32 or float32), and such a data type is always known across the computation. Various methods can create tensors, two of which–that is–**constants and variables** are the most common ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2yc4AMXCC3f",
        "colab_type": "text"
      },
      "source": [
        "*   **Constants**\n",
        "\n",
        "Use methods such as `tf.ones(...)`, `tf.zeros(...)`, `tf.eye(...)`, and etc..\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2NS5woVCJdi",
        "colab_type": "code",
        "outputId": "b8d92234-5671-4d7c-84ea-779ea3009bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a = tf.ones(shape=(2,3), dtype=tf.int32)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 1, 1],\n",
              "       [1, 1, 1]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZCUdl_pDm6o",
        "colab_type": "text"
      },
      "source": [
        "Or define them by manually passing Python/numpy data types ([More info](https://www.tensorflow.org/api_docs/python/tf/constant))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUYZVnZcEA9O",
        "colab_type": "code",
        "outputId": "9eb409ec-30e8-4fde-dc31-542774c1b9f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "b = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"b =\",b);\n",
        "\n",
        "npvar = np.array([\"hello\", \"world\"])\n",
        "c = tf.constant(npvar)\n",
        "print(\"\\nc =\", c)\n",
        "\n",
        "d = tf.constant(10.0, shape=[2,5])\n",
        "print(\"\\nd =\", d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b = tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n",
            "\n",
            "c = tf.Tensor([b'hello' b'world'], shape=(2,), dtype=string)\n",
            "\n",
            "d = tf.Tensor(\n",
            "[[10. 10. 10. 10. 10.]\n",
            " [10. 10. 10. 10. 10.]], shape=(2, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9xm-JZeGU2M",
        "colab_type": "text"
      },
      "source": [
        "You can also use random initializers ([More info](https://www.tensorflow.org/api_docs/python/tf/random)). You may re-run the cell to generate another set of random values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTpw8Xn1KuTx",
        "colab_type": "code",
        "outputId": "2211d576-20bd-4a50-ad72-24c3dac89539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "e = tf.random.normal(shape=[2, 3], mean=0.0, stddev=1.0)\n",
        "print(\"e =\", e)\n",
        "\n",
        "f = tf.random.uniform( shape=[2,3], minval=0,maxval=10,dtype=tf.int32)\n",
        "print(\"\\nf =\", f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "e = tf.Tensor(\n",
            "[[ 0.61113954 -0.258195    1.2110202 ]\n",
            " [-0.39822677 -2.3552241  -3.0503285 ]], shape=(2, 3), dtype=float32)\n",
            "\n",
            "f = tf.Tensor(\n",
            "[[3 3 0]\n",
            " [3 4 7]], shape=(2, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZrV5FsiMkE-",
        "colab_type": "text"
      },
      "source": [
        "*   **Variables**\n",
        "\n",
        "Variables hold a persistant shared state across your computation. The most common use case of Variables is the model's trainable parameters.\n",
        "\n",
        "The only way to create variables is to use `tf.Variable(<required-initial-value>, name=<optional-name>)` class. Tensorflow uses the `initial-value` to infer the shape and the type of the variable. Please note that shape and the type of variable, once specified, cannot be changed during the computation.  Tensorflow cleans up variables when the runtime changes its scope and the variable is not referenced anymore. Therefore, it is your responsibility to keep track of variables in your Tensorflow program (Good news: Tensorflow's high-level APIs handles that automatically)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stnuFXfBSM8q",
        "colab_type": "code",
        "outputId": "cd0689bc-a5a7-4288-96af-8f3b861c7abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "w = tf.Variable(20., name=\"my_var01\")\n",
        "print('w =', w)\n",
        "\n",
        "initializer = tf.initializers.GlorotUniform()\n",
        "x = tf.Variable(initializer(shape=(2, 5)), name=\"my_var02\")\n",
        "print('\\nx =', x)\n",
        "\n",
        "y = tf.Variable(tf.zeros([5]), name='my_var03')\n",
        "print('\\ny =', y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w = <tf.Variable 'my_var01:0' shape=() dtype=float32, numpy=20.0>\n",
            "\n",
            "x = <tf.Variable 'my_var02:0' shape=(2, 5) dtype=float32, numpy=\n",
            "array([[-0.45070884,  0.56897163,  0.29169297, -0.77587044, -0.4456739 ],\n",
            "       [ 0.1657275 , -0.9256539 , -0.86812764,  0.05088377,  0.19746172]],\n",
            "      dtype=float32)>\n",
            "\n",
            "y = <tf.Variable 'my_var03:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gOVcgI_bxCy",
        "colab_type": "text"
      },
      "source": [
        "Variables' APIs are mostly similar to Tensors. Hence, we can treat them like a standard Tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxYFPFB0cvTt",
        "colab_type": "code",
        "outputId": "a4c99c7a-c872-47f9-df1e-1e2b2b8673f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "v = w + 1.  # v is a tf.Tensor and is calculated as the result of\n",
        "            # a mathematical expression that is based on a variable(w).\n",
        "            # tf.Variable gets automatically converted to a tf.Tensor \n",
        "            # representing its value when it is envolved in a expression.\n",
        "\n",
        "print(\"v =\", v)\n",
        "print(f\"v's type = {type(v)}\")\n",
        "print(f\"w's type = {type(w)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v = tf.Tensor(21.0, shape=(), dtype=float32)\n",
            "v's type = <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "w's type = <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvWuU3cne2ch",
        "colab_type": "text"
      },
      "source": [
        "To change the variable's current value, you can use methods such as `assign` and `assign_add`. ([More info](https://www.tensorflow.org/api_docs/python/tf/Variable))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOKSX8wPfVz-",
        "colab_type": "code",
        "outputId": "892d534b-d8c2-4d17-bc26-ea860bb94609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w.assign(v)\n",
        "w.assign_add(v)\n",
        "print('w =', w)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w = <tf.Variable 'my_var01:0' shape=() dtype=float32, numpy=42.0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5cjsMFMcrMA",
        "colab_type": "text"
      },
      "source": [
        "### Rank, Shape, and Type Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSNHYk38csqR",
        "colab_type": "code",
        "outputId": "487399b0-9342-4273-aef8-25635b05c4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(f\"a = \\n{a}\")\n",
        "print(\"a.dtype =\", a.dtype)\n",
        "print(\"a.shape =\", a.shape)\n",
        "print(\"a.rank =\", len(a.shape))\n",
        "# or...\n",
        "print(\"\\na.shape =\", tf.shape(a))\n",
        "print(\"a.rank =\", tf.rank(a)) \n",
        "# What is the difference?\n",
        "\n",
        "print(\"\\ne (before type conversion) =\", e)\n",
        "e_int = tf.cast(e, tf.int32)\n",
        "print(\"e (after type conversion) =\", e_int)\n",
        "\n",
        "# Convert a tf.Tensor object to an np.array instance\n",
        "e_np = e_int.numpy()\n",
        "print(f\"\\ntype(e_np) = {type(e_np)}\")\n",
        "e_np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a = \n",
            "[[1 1 1]\n",
            " [1 1 1]]\n",
            "a.dtype = <dtype: 'int32'>\n",
            "a.shape = (2, 3)\n",
            "a.rank = 2\n",
            "\n",
            "a.shape = tf.Tensor([2 3], shape=(2,), dtype=int32)\n",
            "a.rank = tf.Tensor(2, shape=(), dtype=int32)\n",
            "\n",
            "e (before type conversion) = tf.Tensor(\n",
            "[[ 0.61113954 -0.258195    1.2110202 ]\n",
            " [-0.39822677 -2.3552241  -3.0503285 ]], shape=(2, 3), dtype=float32)\n",
            "e (after type conversion) = tf.Tensor(\n",
            "[[ 0  0  1]\n",
            " [ 0 -2 -3]], shape=(2, 3), dtype=int32)\n",
            "\n",
            "type(e_np) = <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  1],\n",
              "       [ 0, -2, -3]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1XDVK87pb7s",
        "colab_type": "text"
      },
      "source": [
        "### Tensor manipulation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRKFd5keq3fv",
        "colab_type": "text"
      },
      "source": [
        "**Element-Wise Operations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bExs9Pl7pgFP",
        "colab_type": "code",
        "outputId": "e511ff74-8b81-4e26-b465-b163dd1ad153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "t1 = tf.constant([[0, 0, 0], [0, 1, 1], [0, 1, 1]])\n",
        "t2 = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print('t1 + t2 =', t1 + t2)\n",
        "print('t2 - t1 =', t2 - t1)\n",
        "print('t1 * t2 =', t1 * t2)\n",
        "print('t1 / t2 =', t1 / t2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t1 + t2 = tf.Tensor(\n",
            "[[ 1  2  3]\n",
            " [ 4  6  7]\n",
            " [ 7  9 10]], shape=(3, 3), dtype=int32)\n",
            "t2 - t1 = tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 4 5]\n",
            " [7 7 8]], shape=(3, 3), dtype=int32)\n",
            "t1 * t2 = tf.Tensor(\n",
            "[[0 0 0]\n",
            " [0 5 6]\n",
            " [0 8 9]], shape=(3, 3), dtype=int32)\n",
            "t1 / t2 = tf.Tensor(\n",
            "[[0.         0.         0.        ]\n",
            " [0.         0.2        0.16666667]\n",
            " [0.         0.125      0.11111111]], shape=(3, 3), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jOlnr9MrN1_",
        "colab_type": "text"
      },
      "source": [
        "**Broadcasting** Broadcasting happens in arithmetic operations encountering tensors with different shapes. Basically, Tensorflow \"broadcasts\" the smaller tensor across the larger matrix so that they become compatible. Think of broadcasting as repeating the values of the smaller tensor without actually needlessly copying them. In fact, Broadcasting provides an easy way to implement algorithms efficiently.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://raw.githubusercontent.com/kazemnejad/tensorflow-2-tutorial/master/resources/part_01_broadcasting.jpg\" width=\"500\" />\n",
        "\n",
        "<a href=\"https://www.tutorialspoint.com/numpy/numpy_broadcasting.htm\">[source]</a>\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEn5nvS8rBNu",
        "colab_type": "code",
        "outputId": "4c19cbdd-26e8-47b7-d711-8980c4a6a8be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "t1 = tf.constant([1, 2, 3, 4])\n",
        "print(\"t1 + 100 =\", t1 + 100)\n",
        "\n",
        "# (m, n) + (1, n)\n",
        "t1 = tf.constant([[1, 2, 3], \n",
        "                  [4, 5, 6]])\n",
        "t2 = tf.constant([[100, 200, 300]])\n",
        "print(f\"\\nt1.shape = {t1.shape}, t2.shape = {t2.shape}\")\n",
        "print(\"t1 + t2 =\", t1 + t2)\n",
        "\n",
        "# (m, n) + (n, 1)\n",
        "t1 = tf.constant([[1, 2, 3], \n",
        "                  [4, 5, 6]])\n",
        "t2 = tf.constant([[100], \n",
        "                  [200]])\n",
        "print(f\"\\nt1.shape = {t1.shape}, t2.shape = {t2.shape}\")\n",
        "print(\"t1 + t2 =\", t1 + t2)\n",
        "\n",
        "# (1, n) + (m, 1)\n",
        "t1 = tf.constant([[1, 2, 3]])\n",
        "t2 = tf.constant([[100], \n",
        "                  [200]])\n",
        "print(f\"\\nt1.shape = {t1.shape}, t2.shape = {t2.shape}\")\n",
        "print(\"t1 + t2 =\", t1 + t2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t1 + 100 = tf.Tensor([101 102 103 104], shape=(4,), dtype=int32)\n",
            "\n",
            "t1.shape = (2, 3), t2.shape = (1, 3)\n",
            "t1 + t2 = tf.Tensor(\n",
            "[[101 202 303]\n",
            " [104 205 306]], shape=(2, 3), dtype=int32)\n",
            "\n",
            "t1.shape = (2, 3), t2.shape = (2, 1)\n",
            "t1 + t2 = tf.Tensor(\n",
            "[[101 102 103]\n",
            " [204 205 206]], shape=(2, 3), dtype=int32)\n",
            "\n",
            "t1.shape = (1, 3), t2.shape = (2, 1)\n",
            "t1 + t2 = tf.Tensor(\n",
            "[[101 102 103]\n",
            " [201 202 203]], shape=(2, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8AkyPpY4HF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General Rule\n",
        "\n",
        "# 1.  (m, n) matrix    +, -, *, /    (1, n) matrix   =(get copied)=>   (m, n)\n",
        "# 2.  (m, n) matrix    +, -, *, /    (m, 1) matrix   =(get copied)=>   (m, n)\n",
        "# 2.  (m, n) matrix    +, -, *, /    0D scalar       =(get copied)=>   (m, n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y033tsFV5ss1",
        "colab_type": "text"
      },
      "source": [
        "**Matrix Multiplication**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GVHPoFP572U",
        "colab_type": "code",
        "outputId": "46ef2cd7-a4b1-4d32-b436-b8f89055a55b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "t1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "t2 = tf.constant([[10, 20], \n",
        "                  [30, 40],\n",
        "                  [50, 60]])\n",
        "print(\"tf.matmul(t1, t2) =\", tf.matmul(t1, t2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.matmul(t1, t2) = tf.Tensor(\n",
            "[[2200 2800]\n",
            " [4900 6400]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6iQt6ij7pnl",
        "colab_type": "text"
      },
      "source": [
        "**Transposing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pFJHnUe72mq",
        "colab_type": "code",
        "outputId": "24c39655-9ac3-46a5-9552-e18a2aca357c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# tf.transpose(t, perm) permutes the dimensions according to the `perm` parameter.\n",
        "t1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"tf.transpose(t1, [1, 0]) =\", tf.transpose(t1, perm=[1, 0])) \n",
        "\n",
        "# It also works in higher dimensions\n",
        "t1 = tf.ones(shape=(2, 5, 13))\n",
        "t1_t = tf.transpose(t1, perm=[0, 2, 1])\n",
        "print(f\"\\nt1_t.shape = {t1_t.shape}\")\n",
        "\n",
        "# You can permute the order of more than two dimensions at the same time.\n",
        "t1 = tf.ones(shape=(2, 5, 13))\n",
        "t1_t = tf.transpose(t1, perm=[2, 0, 1])\n",
        "print(f\"\\nt1_t.shape = {t1_t.shape}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.transpose(t1, [1, 0]) = tf.Tensor(\n",
            "[[1 4]\n",
            " [2 5]\n",
            " [3 6]], shape=(3, 2), dtype=int32)\n",
            "\n",
            "t1_t.shape = (2, 13, 5)\n",
            "\n",
            "t1_t.shape = (13, 2, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj4u0FAS_HGi",
        "colab_type": "text"
      },
      "source": [
        "**Reshaping**\n",
        "You can create a new tensor from an existing tensor with different shape but same values. The only rule is that the new tensor's size should be equal to that of the previous one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exFO5ad3_KV7",
        "colab_type": "code",
        "outputId": "a34517b7-8c8d-4674-c7f7-91b42fc56d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Examples from https://www.tensorflow.org/api_docs/python/tf/reshape\n",
        "\n",
        "t = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9]) # [9]\n",
        "print(f\"t_new = tf.reshape(t, [3, 3]); t_new => \\n {tf.reshape(t, [3, 3])}\")\n",
        "\n",
        "t = tf.constant([[[1, 1], [2, 2]],\n",
        "                [[3, 3], [4, 4]]]) # [2, 2, 2]\n",
        "print(f\"\\nt_new = tf.reshape(t, [2, 4]); t_new => \\n {tf.reshape(t, [2, 4])}\")\n",
        "\n",
        "# -1 can also be used to automatically calculate the shape\n",
        "t = tf.constant([[[1, 1, 1],\n",
        "                 [2, 2, 2]],\n",
        "                [[3, 3, 3],\n",
        "                 [4, 4, 4]],\n",
        "                [[5, 5, 5],\n",
        "                 [6, 6, 6]]]) # [3, 2, 3]\n",
        "\n",
        "# -1 => 18\n",
        "print(f\"\\nt_new = tf.reshape(t, [-1]); t_new => \\n {tf.reshape(t, [-1])}\")\n",
        "# -1 => 9\n",
        "print(f\"\\nt_new = tf.reshape(t, [2, -1]); t_new => \\n {tf.reshape(t, [2, -1])}\")\n",
        "# -1 => 2\n",
        "print(f\"\\nt_new = tf.reshape(t, [-1, 9]); t_new => \\n {tf.reshape(t, [-1, 9])}\")\n",
        "# -1 => 3\n",
        "print(f\"\\nt_new = tf.reshape(t, [2, -1, 3]); t_new => \\n {tf.reshape(t, [2, -1, 3])}\")\n",
        "\n",
        "# Convert to a scalar using shape `[]`\n",
        "t = tf.constant([5])\n",
        "print(f\"\\nt_new = tf.reshape(t, []); t_new => \\n {tf.reshape(t, [])}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_new = tf.reshape(t, [3, 3]); t_new => \n",
            " [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "\n",
            "t_new = tf.reshape(t, [2, 4]); t_new => \n",
            " [[1 1 2 2]\n",
            " [3 3 4 4]]\n",
            "\n",
            "t_new = tf.reshape(t, [-1]); t_new => \n",
            " [1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6]\n",
            "\n",
            "t_new = tf.reshape(t, [2, -1]); t_new => \n",
            " [[1 1 1 2 2 2 3 3 3]\n",
            " [4 4 4 5 5 5 6 6 6]]\n",
            "\n",
            "t_new = tf.reshape(t, [-1, 9]); t_new => \n",
            " [[1 1 1 2 2 2 3 3 3]\n",
            " [4 4 4 5 5 5 6 6 6]]\n",
            "\n",
            "t_new = tf.reshape(t, [2, -1, 3]); t_new => \n",
            " [[[1 1 1]\n",
            "  [2 2 2]\n",
            "  [3 3 3]]\n",
            "\n",
            " [[4 4 4]\n",
            "  [5 5 5]\n",
            "  [6 6 6]]]\n",
            "\n",
            "t_new = tf.reshape(t, []); t_new => \n",
            " 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-oTkq95EA3B",
        "colab_type": "text"
      },
      "source": [
        "**Advanced Reshaping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdZYfQxOEKqI",
        "colab_type": "code",
        "outputId": "bac886a2-1756-49c8-8ac0-c5226b91a732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# tf.tile(t, multiples) creates a new tensor by replicating `t` `multiples` times.\n",
        "t = tf.constant([1, 2, 3, 4]) # [4]\n",
        "print(f\"tf.tile(t, [2]) = \\n{tf.tile(t, [2])}\") # [8]\n",
        "\n",
        "t = tf.constant([[1, 2, 3, 4]]) # [1, 4]\n",
        "print(f\"\\ntf.tile(t, [3, 1]) = \\n{tf.tile(t, [3, 1])}\") # [3, 4]\n",
        "\n",
        "# tf.expand(t, axis) adds a new dimension to the tensor's shape (tensor's values does not change)\n",
        "# Examples from https://www.tensorflow.org/api_docs/python/tf/expand_dims\n",
        "\n",
        "t1 = tf.constant([1, 2,])\n",
        "print(f\"\\ntf.shape(tf.expand_dims(t1, 0)) = {tf.shape(tf.expand_dims(t1, 0))}\")\n",
        "print(f\"tf.shape(tf.expand_dims(t1, 1)) = {tf.shape(tf.expand_dims(t1, 1))}\")\n",
        "print(f\"tf.shape(tf.expand_dims(t1, -1)) = {tf.shape(tf.expand_dims(t1, -1))}\")\n",
        "\n",
        "# 't2' is a tensor of shape [2, 3, 5]\n",
        "t2 = tf.ones(shape=[2, 3, 5])\n",
        "print(f\"\\ntf.shape(tf.expand_dims(t2, 0)) = {tf.shape(tf.expand_dims(t2, 0))}\")\n",
        "print(f\"tf.shape(tf.expand_dims(t2, 2)) = {tf.shape(tf.expand_dims(t2, 2))}\")\n",
        "print(f\"tf.shape(tf.expand_dims(t2, 3)) = {tf.shape(tf.expand_dims(t2, 3))}\")\n",
        "\n",
        "# tf.squeeze(a) exactly do the reverse operation: Removes all dimensions of size 1\n",
        "t3 = tf.ones(shape=[1, 2, 1, 3, 1, 1])\n",
        "print(f\"\\ntf.shape(tf.squeeze(t3)) = {tf.shape(tf.squeeze(t3))}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.tile(t, [2]) = \n",
            "[1 2 3 4 1 2 3 4]\n",
            "\n",
            "tf.tile(t, [3, 1]) = \n",
            "[[1 2 3 4]\n",
            " [1 2 3 4]\n",
            " [1 2 3 4]]\n",
            "\n",
            "tf.shape(tf.expand_dims(t1, 0)) = [1 2]\n",
            "tf.shape(tf.expand_dims(t1, 1)) = [2 1]\n",
            "tf.shape(tf.expand_dims(t1, -1)) = [2 1]\n",
            "\n",
            "tf.shape(tf.expand_dims(t2, 0)) = [1 2 3 5]\n",
            "tf.shape(tf.expand_dims(t2, 2)) = [2 3 1 5]\n",
            "tf.shape(tf.expand_dims(t2, 3)) = [2 3 5 1]\n",
            "\n",
            "tf.shape(tf.squeeze(t3)) = [2 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBE9vZIBJwnu",
        "colab_type": "text"
      },
      "source": [
        "**Combining Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4UURPTCJ0hK",
        "colab_type": "code",
        "outputId": "0a76156a-4f0b-4a87-9d2b-af5cb0cec750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "t1 = tf.constant([[1, 1, 1], [1, 1, 1]]) # [2, 3]\n",
        "t2 = tf.constant([[2, 2, 2], [2, 2, 2]]) # [2, 3]\n",
        "t3 = tf.constant([[3, 3, 3], [3, 3, 3]]) # [2, 3]\n",
        "\n",
        "print(f\"tf.concat([t1, t2, t3], axis=0) = \\n{tf.concat([t1, t2, t3], axis=0)}\") # [6, 3]\n",
        "print(f\"\\ntf.concat([t1, t2, t3], axis=1) = \\n{tf.concat([t1, t2, t3], axis=1)}\") # [2, 9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.concat([t1, t2, t3], axis=1) = \n",
            "[[1 1 1]\n",
            " [1 1 1]\n",
            " [2 2 2]\n",
            " [2 2 2]\n",
            " [3 3 3]\n",
            " [3 3 3]]\n",
            "\n",
            "tf.concat([t1, t2, t3], axis=1) = \n",
            "[[1 1 1 2 2 2 3 3 3]\n",
            " [1 1 1 2 2 2 3 3 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Ma3MQoL4aM",
        "colab_type": "code",
        "outputId": "8d9d3afc-e020-4304-ed7d-ad882221d143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "t1 = tf.constant([1, 1, 1, 1])\n",
        "t2 = tf.constant([2, 2, 2, 2])\n",
        "t3 = tf.constant([3, 3, 3, 3])\n",
        "\n",
        "print(f\"tf.stack([t1, t2, t3], axis=0) = \\n{tf.stack([t1, t2, t3], axis=0)}\")\n",
        "print(f\"\\ntf.stack([t1, t2, t3], axis=1) = \\n{tf.stack([t1, t2, t3], axis=1)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.stack([t1, t2, t3], axis=1) = \n",
            "[[1 1 1 1]\n",
            " [2 2 2 2]\n",
            " [3 3 3 3]]\n",
            "\n",
            "tf.stack([t1, t2, t3], axis=1) = \n",
            "[[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7UMU3S9UYR0",
        "colab_type": "text"
      },
      "source": [
        "**Slicing and Indexing** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHRH6qCuUcmO",
        "colab_type": "code",
        "outputId": "d5fd4731-f82b-4b9e-8da5-262141487380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "t = tf.random.uniform(shape=[4, 5, 6, 7], maxval=10, dtype=tf.int32)\n",
        "\n",
        "# same as Python lists and Numpy arrays\n",
        "t1 = t[1:3, 0, 3:, -2:-6:-1]\n",
        "print(\"t1 =\", t1)\n",
        "\n",
        "# same t[0, 0, :, :]\n",
        "t2 = t[0, :, :, 0]\n",
        "print(\"\\nt2 =\", t2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t1 = tf.Tensor(\n",
            "[[[0 5 5 2]\n",
            "  [0 6 9 0]\n",
            "  [1 8 5 5]]\n",
            "\n",
            " [[0 7 8 7]\n",
            "  [9 2 8 1]\n",
            "  [9 9 0 3]]], shape=(2, 3, 4), dtype=int32)\n",
            "\n",
            "t2 = tf.Tensor(\n",
            "[[4 2 6 5 8 5]\n",
            " [4 2 1 7 6 7]\n",
            " [6 8 6 1 5 1]\n",
            " [9 4 6 0 0 9]\n",
            " [5 9 0 2 7 8]], shape=(5, 6), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdzaDvhiXXT_",
        "colab_type": "text"
      },
      "source": [
        "**Reducing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUhu0AVkXZuQ",
        "colab_type": "code",
        "outputId": "05217ecd-f8f3-4fa2-f83b-4932cf6cd644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "t = tf.constant([[1, 2, 3, 4], \n",
        "                 [1, 2, 3, 4]])\n",
        "\n",
        "# calculate the sum of all elements\n",
        "print(\"tf.reduce_sum(t) =\", tf.math.reduce_sum(t))\n",
        "\n",
        "# calculate the sum of all elements vertically \n",
        "print(\"tf.reduce_sum(t, axis=0) =\", tf.math.reduce_sum(t, axis=0))\n",
        "\n",
        "# calculate the sum of all elements horizontally\n",
        "print(\"tf.reduce_sum(t, axis=1) =\", tf.math.reduce_sum(t, axis=1))\n",
        "\n",
        "t1 = tf.random.uniform(shape=[3, 4], maxval=10, dtype=tf.int32)\n",
        "print(\"\\n\",t1)\n",
        "print(\"tf.reduce_min(t1) =\", tf.math.reduce_min(t1))\n",
        "print(\"tf.reduce_max(t1) =\", tf.math.reduce_max(t1))\n",
        "print(\"tf.reduce_mean(t1) =\", tf.math.reduce_mean(t1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.reduce_sum(t) = tf.Tensor(20, shape=(), dtype=int32)\n",
            "tf.reduce_sum(t, axis=0) = tf.Tensor([2 4 6 8], shape=(4,), dtype=int32)\n",
            "tf.reduce_sum(t, axis=1) = tf.Tensor([10 10], shape=(2,), dtype=int32)\n",
            "\n",
            " tf.Tensor(\n",
            "[[8 5 0 3]\n",
            " [5 0 6 6]\n",
            " [9 6 8 2]], shape=(3, 4), dtype=int32)\n",
            "tf.reduce_min(t1) = tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.reduce_max(t1) = tf.Tensor(9, shape=(), dtype=int32)\n",
            "tf.reduce_mean(t1) = tf.Tensor(4, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOKsuSFHPJPI",
        "colab_type": "text"
      },
      "source": [
        "## 3. Auto Differentiation\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bZ6N-jxiCFr",
        "colab_type": "text"
      },
      "source": [
        "# Assignment!\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAHBy9xcPPib",
        "colab_type": "text"
      },
      "source": [
        "## References"
      ]
    }
  ]
}