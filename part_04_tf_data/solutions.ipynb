{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part_04_solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iust-deep-learning/tensorflow-2-tutorial/blob/master/part_05_tf_data/solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8LoLU0OQha",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow 2.0 Tutorial: Part #5\n",
        "\n",
        "\n",
        "TensorFlow 2.0 Tutorial by IUST\n",
        "\n",
        "*   Last Update: Dec 2019\n",
        "*   Official Page: https://github.com/iust-deep-learning/tensorflow-2-tutorial\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSj39l8gcIA8",
        "colab_type": "text"
      },
      "source": [
        "Please run the following cell before going through the rest of the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFC1dEyMcFq2",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "dcdda310-5c8e-45c7-d90f-5790ede41b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from pprint import pprint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eGHQmDwsZhWh"
      },
      "source": [
        "## Time Series data pipeline\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzJ99c_QhPI2",
        "colab_type": "text"
      },
      "source": [
        "### Exercise #1: Time Series data pipeline\n",
        "A time series is a series of data points indexed in time order. One example of time series is stock prices at regular intervals of time (hourly, daily, etc.).\n",
        "In this exercise we are going to create a TensorFlow dataset to generate proper input for a time series prediction problem. In a time series problem, given data points in [i : i+window], we want to predict time_series[i+window+1] as output.\n",
        "\n",
        "Now, suppose our series is numbers in range 0 to 30:\n",
        "- First, filter all non-prime numbers from dataset using **dataset.filter** functionality :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8REnvFnnMuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series = np.arange (300, dtype=np.int32) #initial series\n",
        "\n",
        "###### implementation ######\n",
        "pre_computed_prime_numbers = tf.constant(..., dtype=tf.int32) \n",
        "###### implementation ######\n",
        "\n",
        "###### implementation ######\n",
        "# tf.math.equal\n",
        "# tf.math.reduce_any\n",
        "def is_prime (element):\n",
        "  raise NotImplemented()\n",
        "###### implementation ######\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(series, )\n",
        "dataset = dataset.filter(is_prime)\n",
        "for elem in dataset:\n",
        "  print(elem.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MmLsDxfELh-S"
      },
      "source": [
        "Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TUnGVQzNLh-I",
        "colab": {}
      },
      "source": [
        "series = np.arange (300, dtype=np.int32) #initial series\n",
        "\n",
        "###### implementation ######\n",
        "def is_prime_py (element):\n",
        "  flag = True\n",
        "  val = element\n",
        "  if val <= 1:\n",
        "      flag =  False\n",
        "  for i in range (2, val):\n",
        "    if val % i == 0:\n",
        "      flag =  False\n",
        "      break        \n",
        "  return flag\n",
        "\n",
        "pre_computed_prime_numbers = tf.constant([x for x in series if is_prime_py(x)], dtype=tf.int32) \n",
        "###### implementation ######\n",
        "\n",
        "###### implementation ######\n",
        "def is_prime (element):\n",
        "  check = tf.math.equal(pre_computed_prime_numbers, element)\n",
        "  return tf.math.reduce_any(check)\n",
        "###### implementation ######\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(series, )\n",
        "dataset = dataset.filter(is_prime)\n",
        "for elem in dataset:\n",
        "  print(elem.numpy())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiCzCk4S0cJM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Now, create a dataset for this problem, so that\n",
        "\n",
        "Given\n",
        "- A window size\n",
        "\n",
        "We can get \n",
        "- series[i : i+window] as input and series[i+window+1] as output in i-th iteration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doiu6tavfjWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### implementation ######\n",
        "# dataset.batch(...)\n",
        "# dataset.skip(...)\n",
        "# dataset.map(...)\n",
        "# tf.data.Dataset.zip()\n",
        "###### implementation ######\n",
        "\n",
        "for f, l in predict_next_step:\n",
        "  print(f.numpy(),'-->', l.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mcSQHeVTLhTO"
      },
      "source": [
        "Solutions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sBbmJ0UpLhTC",
        "colab": {}
      },
      "source": [
        "###### implementation ######\n",
        "window_size = 3\n",
        "features = dataset.batch (window_size, drop_remainder=True)\n",
        "labels = dataset.batch(window_size).skip(1).map(lambda batch: batch[0])\n",
        "predict_next_step = tf.data.Dataset.zip((features, labels))\n",
        "###### implementation ######\n",
        "\n",
        "for f, l in predict_next_step:\n",
        "  print(f.numpy(),'-->', l.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tXo0f6BgZhYU"
      },
      "source": [
        "## References\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1DT_2hsJ1_gl"
      },
      "source": [
        "\n"
      ]
    }
  ]
}